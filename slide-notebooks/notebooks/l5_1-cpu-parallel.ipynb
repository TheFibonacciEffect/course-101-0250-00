{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "_Lecture 5_\n",
    "# Parallel computing (on CPUs) and performance assessment"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### The goal of this lecture 5 is to introduce:\n",
    "- Performance limiters\n",
    "- Effective memory throughput metric $T_\\mathrm{eff}$"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Parallel computing on CPUs\n",
    "- Shared memory parallelisation"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "fragment"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Performance limiters\n",
    "\n",
    "### Hardware\n",
    "- Multi-core CPUs (and GPUs) are throughput-oriented systems\n",
    "- They use their massive parallelism to hide latency"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "*Recall from [lecture 1](lecture1/#why_we_do_it) ...*"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "fragment"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Use **parallel computing** (to address this):\n",
    "- The \"memory wall\" in ~ 2004\n",
    "- Single-core to multi-core devices\n",
    "\n",
    "![mem_wall](./figures/mem_wall.png)"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "GPUs are massively parallel devices\n",
    "- SIMD machine (programmed using threads - SPMD) ([more](https://safari.ethz.ch/architecture/fall2020/lib/exe/fetch.php?media=onur-comparch-fall2020-lecture24-simdandgpu-afterlecture.pdf))\n",
    "- Further increases the Flop vs Bytes gap\n",
    "\n",
    "![cpu_gpu_evo](./figures/cpu_gpu_evo.png)"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "If we look at an\n",
    "- Nvidia Tesla A100 GPU\n",
    "- AMD EPYC \"Rome\" 7282 (16 cores) CPU\n",
    "\n",
    "| Device | TFLOPS (FP64) | Memory BW TB/s | Ratio |\n",
    "| :------: | :-----: | :------: | :------: |\n",
    "| Tesla A100 | 9.7 | 1.55 | 6.23\n",
    "| AMD EPYC 7282 | 0.7 | 0.085 | 8.23"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "âž¡ Memory bound: requires to re-think the numerical implementation and solution strategies"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "fragment"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### On the scientific application side\n",
    "\n",
    "- Most algorithms require only a few operations or flops ...\n",
    "- ... compared to the amount of numbers or bytes accessed from main memory."
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "First derivative example"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "fragment"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "If we \"naively\" compare the \"cost\" of evaluating a finite-difference first derivative, e.g., computing a flux $q$:\n",
    "\n",
    "$$q = -D~\\frac{âˆ‚A}{âˆ‚x}~,$$\n",
    "\n",
    "which in the discrete form reads `q[ix] = -D*(A[ix+1]-A[ix])/dx`."
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The cost of evaluating `q[ix] = -D*(A[ix+1]-A[ix])/dx`:\n",
    "\n",
    "2 reads + 1 write => $3 Ã— 8$ = **24 bytes transferred**\n",
    "\n",
    "1 (fused) addition and division => **1 (2) floating point operations**"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "assuming:\n",
    "- $D$, $âˆ‚x$ are scalars\n",
    "- $q$ and $A$ are arrays of `Float64` (read from global memory)"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "fragment"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Comparing to the machine balances:\n",
    "\n",
    "| Device | TFLOPS (FP64) | Memory BW TB/s | Ratio |\n",
    "| :------: | :-----: | :------: | :------: |\n",
    "| Tesla A100 | 9.7 | 1.55 | 6.23 |\n",
    "| AMD EPYC 7282 | 0.7 | 0.085 | 8.23 |\n",
    "| $âˆ‚A/âˆ‚x$ | 1 ($Ã—10^{-12}$) | 24 ($Ã—10^{-12}$) | 0.041 |"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "0.041 << 6.23 or 8.23, and so we are memory-bound"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "fragment"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The Flop/s metric is no longer the most adequate for reporting the application performance of many modern applications."
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Effective memory throughput metric\n",
    "\n",
    "Need for a memory throughput-based performance evaluation metric: $T_\\mathrm{eff}$ [GB/s]\n",
    "\n",
    "âž¡ Evaluate the performance of iterative stencil-based solvers."
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The effective memory access $A_\\mathrm{eff}$ [GB]\n",
    "\n",
    "Sum of:\n",
    "- twice the memory footprint of the unknown fields, $D_\\mathrm{u}$, (fields that depend on their own history and that need to be updated every iteration)\n",
    "- known fields, $D_\\mathrm{k}$, that do not change every iteration."
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The effective memory access divided by the execution time per iteration, $t_\\mathrm{it}$ [sec], defines the effective memory throughput, $T_\\mathrm{eff}$ [GB/s]:\n",
    "\n",
    "$$ A_\\mathrm{eff} = 2~D_\\mathrm{u} + D_\\mathrm{k} $$\n",
    "\n",
    "$$ T_\\mathrm{eff} = \\frac{A_\\mathrm{eff}}{t_\\mathrm{it}} $$"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "fragment"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The upper bound of $T_\\mathrm{eff}$ is $T_\\mathrm{peak}$ as measured, e.g., by [McCalpin, 1995](https://www.researchgate.net/publication/51992086_Memory_bandwidth_and_machine_balance_in_high_performance_computers) for CPUs or a GPU analogue.\n",
    "\n",
    "Defining the $T_\\mathrm{eff}$ metric, we assume that\n",
    "1. we evaluate an iterative stencil-based solver,\n",
    "2. the problem size is much larger than the cache sizes and\n",
    "3. the usage of time blocking is not feasible or advantageous (reasonable for real-world applications)."
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> ðŸ’¡ note: Fields within the effective memory access that do not depend on their own history; such fields can be re-computed on the fly or stored on-chip."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As first task, we'll compute the $T_\\mathrm{eff}$ for the 2D diffusion code [`diffusion_2D.jl`](https://github.com/eth-vaw-glaciology/course-101-0250-00/blob/main/scripts/) we are already familiar with (download the script if needed to get started)."
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We'll have to:\n",
    "- copy `diffusion_2D.jl` and rename it to `diffusion_2D_Teff.jl`\n",
    "- add a timer\n",
    "- include the performance metric formulas\n",
    "- deactivate visualisation\n",
    "\n",
    "ðŸ’» Let's get started"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "fragment"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Timer and performance\n",
    "- Use `Base.time()` to return the current timestamp\n",
    "- Define `t_tic`, the starting time, after 11 time steps to allow for \"warmup\"\n",
    "- Record the exact number of iterations (introduce e.g. `niter`)\n",
    "- Compute the elapsed time `t_toc` at the end of the time loop and report:\n",
    "\n",
    "```julia\n",
    "t_toc = ...\n",
    "A_eff = ...          # Effective main memory access per iteration [GB]\n",
    "t_it  = ...          # Execution time per iteration [s]\n",
    "T_eff = A_eff/t_it   # Effective memory throughput [GB/s]\n",
    "```"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Report `t_toc`, `T_Eff` and `niter` at the end of the code, formatting output using `@printf()` macro.\n",
    "- Round `T_eff` to the 3rd significant digit.\n",
    "\n",
    "```julia\n",
    "@printf(\"Time = %1.3f sec, ... \\n\", t_toc, ...)\n",
    "```"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Deactivate visualisation\n",
    "- Use keyword arguments (\"kwargs\") to allow for default behaviour\n",
    "- Define a `do_visu` flag set to `false`\n",
    "\n",
    "```julia\n",
    "@views function diffusion_2D(; ??)\n",
    "\n",
    "   ...\n",
    "\n",
    "    return\n",
    "end\n",
    "\n",
    "diffusion_2D(; ??)\n",
    "```"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "So far so good, we have now a timer.\n",
    "\n",
    "Let's also boost resolution to `nx = ny = 512` and set `ttot = 0.1` to have the code running ~1 sec.\n",
    "\n",
    "In the next part, we'll work on a multi-threading implementation."
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Parallel computing on CPUs\n",
    "\n",
    "_Towards implementing shared memory parallelisation using multi-threading capabilities of modern multi-core CPUs._"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We'll work it out in 4 steps:\n",
    "1. Precomputing scalars, removing divisions and casual arrays\n",
    "2. Replacing flux arrays by macros\n",
    "3. Back to loops I\n",
    "4. Back to loops II - compute functions (kernels)"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "fragment"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Precomputing scalars, removing divisions and casual arrays\n",
    "\n",
    "As first, duplicate `diffusion_2D_Teff.jl` and rename it as `diffusion_2D_perf.jl`"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- First, replace `D/dx` and `D/dy` in the flux calculations by precomputed `D_dx = D/dx` and `D_dy = D/dy` in the fluxes.\n",
    "- Then, replace divisions `/dx, /dy` by inverse multiplications `*_dx, *_dy` where `_dx, _dy = 1.0/dx, 1.0/dy`.\n",
    "- Remove the `dCdt` array as we do not actually need it in the algorithm."
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "fragment"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Replacing flux arrays by macros\n",
    "\n",
    "As first, duplicate `diffusion_2D_perf.jl` and rename it as `diffusion_2D_perf2.jl`"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Storing flux calculations in `qx` and `qy` arrays is not needed and produces additional read/write we want to avoid.\n",
    "\n",
    "Let's create macros and call them in the time loop:\n",
    "\n",
    "```julia\n",
    "macro qx()  esc(:( ... )) end\n",
    "macro qy()  esc(:( ... )) end\n",
    "```"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "fragment"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Macro will be expanded at preprocessing stage (copy-paste)\n",
    "\n",
    "Advantages of using macros vs functions:\n",
    "- easier syntax (no need to specify indices)\n",
    "- there can be a performance advantage (if functions are not inlined)"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Also, we now have to ensure `C` is not read and written back in the same (will become important when enabling multi-threading).\n",
    "\n",
    "Define `C2`, a copy of `C`, modify the physics computation line, and implement a pointer swap\n",
    "\n",
    "```julia\n",
    "C2      = ...\n",
    "# [...]\n",
    "C2[2:end-1,2:end-1] .= C[2:end-1,2:end-1] .- dt.*( ... )\n",
    "C, C2 = ... # pointer swap\n",
    "```"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "fragment"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Back to loops I\n",
    "\n",
    "As first, duplicate `diffusion_2D_perf2.jl` and rename it as `diffusion_2D_perf_loop.jl`"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The goal is now to write out the diffusion physics in a loop fashion over $x$ and $y$ dimensions.\n",
    "\n",
    "Implement a nested loop, taking car of bounds and staggering.\n",
    "\n",
    "```julia\n",
    "for iy=1:??\n",
    "    for ix=1:??\n",
    "        C2[??] = C[??] - dt*( (@qx(ix+1,iy) - @qx(ix,iy))*_dx + (@qy(ix,iy+1) - @qy(ix,iy))*_dy )\n",
    "    end\n",
    "end\n",
    "```"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "fragment"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note that macros can take arguments, here `ix,iy`, and need updated definition.\n",
    "\n",
    "Macro argument can be used in definition appending `$`.\n",
    "\n",
    "```julia\n",
    "macro qx(ix,iy)  esc(:( ... C[$ix+1,$iy+1] ... )) end\n",
    "macro qy(ix,iy)  ...\n",
    "```"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Performance is already quite better with the loop version. Reasons are that `diff()` are allocating tmp and that Julia is overall well optimised for executing loops.\n",
    "\n",
    "Let's now implement the final step."
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4. Back to loops II\n",
    "\n",
    "Duplicate `diffusion_2D_perf2_loop.jl` and rename it as `diffusion_2D_perf_loop_fun.jl`"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this last step, the goal is to define a `compute` function to hold the physics calculations, and to call it within the time loop."
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "fragment"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create a `compute!()` function that takes input and output arrays and needed scalars as argument and returns nothing.\n",
    "\n",
    "```julia\n",
    "function compute!(...)\n",
    "    ...\n",
    "    return\n",
    "end\n",
    "```"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> ðŸ’¡ note: Function that modify arguments take a `!` in their name, a Julia convention."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The `compute!()` function can then be called within the time loop\n",
    "\n",
    "```julia\n",
    "compute!(...)\n",
    "```"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This last implementation executes a bit faster as previous one, as functions allow Julia to further optimise during just-ahead-of-time compilation."
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's now see how to implement multi-threading and advanced vector instructions (AVX)"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "fragment"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Multi-threading (native)\n",
    "\n",
    "Julia ships with it's `base` feature the possibility to enable [multi-threading](https://docs.julialang.org/en/v1/manual/multi-threading/)."
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The only 2 modifications needed to enable it in our code are:\n",
    "\n",
    "1. Place `Threads.@threads` in front of the outer loop definition\n",
    "2. Export the desired amount of threads, e.g., `export JULIA_NUM_THREADS=4`, to be activate prior to launching Julia (or executing the script from the shell)"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "fragment"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> ðŸ’¡ note: For optimal performance, the numbers of threads should be identical to the  number of physical cores of the target CPU."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Multi-threading and AVX\n",
    "\n",
    "Relying on Julia's [LoopVectorization.jl](https://github.com/JuliaSIMD/LoopVectorization.jl) package, it is possible to combine multi-threading with AVX optimisations to further exploit shared memory parallelisation capabilities of x86 type of CPUs."
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To enable it in our code:\n",
    "\n",
    "1. Add `using LoopVectorization` at the top of the script\n",
    "2. Replace `Threads.@threads` by `@tturbo` in front of the outer loop in the `compute!()` kernel\n",
    "\n",
    "And here we go ðŸš€"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "fragment"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> ðŸ’¡ note: For optimal performance assessment, bound-checking should be deactivated. This can be achieved by adding `@inbounds` in front of the compute statement, or running the scripts (or launching Julia) with the `--check-bounds=no` option."
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Wrapping-up\n",
    "\n",
    "- We discussed main performance limiters\n",
    "- We implemented the effective memory throughput metric $T_\\mathrm{eff}$\n",
    "- We optimised the Julia 2D diffusion code (multi-threading and AVX)"
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note that for problem sizes fitting in the cache, [LoopVectorization.jl](https://github.com/JuliaSIMD/LoopVectorization.jl)'s `@tturbo` permits to achieve effective memory throughput close to memory copy rates ($T_\\mathrm{peak}$)."
   ],
   "metadata": {
    "name": "A slide ",
    "slideshow": {
     "slide_type": "fragment"
    }
   }
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.3"
  },
  "kernelspec": {
   "name": "julia-1.6",
   "display_name": "Julia 1.6.3",
   "language": "julia"
  }
 },
 "nbformat": 4
}
